# å®‰å…¨ç†è«–èˆ‡ä¼æ¥­åˆè¦æ¡†æ¶
## å¤§å­¸æ•™ç§‘æ›¸ ç¬¬6ç« ï¼šè³‡è¨Šå®‰å…¨èˆ‡æ³•è¦éµå¾ªçš„ç³»çµ±åŒ–è¨­è¨ˆ

**èª²ç¨‹ç·¨è™Ÿ**: CS785 - ä¼æ¥­ç´šæª¢ç´¢å¢å¼·ç”Ÿæˆç³»çµ±
**ç« ç¯€**: ç¬¬6ç«  å®‰å…¨èˆ‡åˆè¦
**å­¸ç¿’æ™‚æ•¸**: 8å°æ™‚
**å…ˆä¿®èª²ç¨‹**: è³‡è¨Šå®‰å…¨åŸºç¤, æ³•è¦éµå¾ª, ç¬¬0-5ç« 
**ä½œè€…**: è³‡è¨Šå®‰å…¨ç ”ç©¶åœ˜éšŠ & åˆè¦å°ˆå®¶çµ„
**æœ€å¾Œæ›´æ–°**: 2025-01-06

---

## ğŸ“š å­¸ç¿’ç›®æ¨™ (Learning Objectives)

å®Œæˆæœ¬ç« å­¸ç¿’å¾Œï¼Œå­¸ç”Ÿæ‡‰èƒ½å¤ :

1. **å®‰å…¨ç†è«–**: æŒæ¡é›¶ä¿¡ä»»æ¶æ§‹å’Œæ·±åº¦é˜²ç¦¦çš„æ•¸å­¸æ¨¡å‹
2. **åˆè¦æ¡†æ¶**: ç†è§£ GDPRã€SOC2ã€HIPAA ç­‰æ³•è¦çš„æŠ€è¡“å¯¦ç¾è¦æ±‚
3. **ç³»çµ±è¨­è¨ˆ**: è¨­è¨ˆç¬¦åˆä¼æ¥­å®‰å…¨æ¨™æº–çš„ RAG ç³»çµ±æ¶æ§‹
4. **é¢¨éšªç®¡ç†**: å»ºç«‹å®Œæ•´çš„å®‰å…¨é¢¨éšªè©•ä¼°å’Œæ‡‰å°æ©Ÿåˆ¶

---

## 1. è³‡è¨Šå®‰å…¨çš„ç†è«–åŸºç¤

### 1.1 é›¶ä¿¡ä»»æ¶æ§‹çš„æ•¸å­¸æ¨¡å‹

#### **é›¶ä¿¡ä»»åŸç†çš„å½¢å¼åŒ–å®šç¾©**

**å®šç¾© 1.1** (é›¶ä¿¡ä»»æ¨¡å‹): é›¶ä¿¡ä»»å®‰å…¨æ¨¡å‹å¯ä»¥å½¢å¼åŒ–ç‚ºè¨ªå•æ§åˆ¶å‡½æ•¸ï¼š

$$\text{Access}(s, r, a) = \bigwedge_{i=1}^{n} \text{Policy}_i(s, r, a, \text{Context})$$

å…¶ä¸­ï¼š
- $s$: ä¸»é«” (ç”¨æˆ¶ã€æœå‹™ã€è¨­å‚™)
- $r$: è³‡æº (æ•¸æ“šã€APIã€ç³»çµ±)
- $a$: å‹•ä½œ (è®€å–ã€å¯«å…¥ã€åŸ·è¡Œ)
- $\text{Context}$: ç’°å¢ƒä¸Šä¸‹æ–‡ (æ™‚é–“ã€åœ°é»ã€è¨­å‚™ç‹€æ…‹)

**åŸå‰‡ 1.1** (é›¶ä¿¡ä»»åŸºæœ¬åŸå‰‡):
1. **æ°¸ä¸ä¿¡ä»»**: $\forall s, r, a: \text{Trust}(s) = \emptyset$
2. **å§‹çµ‚é©—è­‰**: $\forall \text{Access}: \text{Verify}(\text{Identity}, \text{Context}, \text{Policy})$
3. **æœ€å°æ¬Šé™**: $\text{Privilege}(s, r) = \min(\text{Required}, \text{Granted})$

#### **æ·±åº¦é˜²ç¦¦çš„å±¤ç´šæ¨¡å‹**

**å®šç† 1.1** (å®‰å…¨å±¤ç´šç¨ç«‹æ€§): åœ¨ç†æƒ³çš„æ·±åº¦é˜²ç¦¦ç³»çµ±ä¸­ï¼Œå„å®‰å…¨å±¤ç´šæ‡‰æ»¿è¶³ç¨ç«‹æ€§æ¢ä»¶ï¼š

$$P(\text{Breach}_{i+1} | \text{Breach}_i) < P(\text{Breach}_{i+1})$$

å³ä¸Šå±¤è¢«çªç ´ä¸æ‡‰å¢åŠ ä¸‹å±¤è¢«æ”»ç ´çš„æ¦‚ç‡ã€‚

**å®‰å…¨å±¤ç´šå®šç¾©**:

```python
from enum import Enum
from typing import Dict, List, Optional, Any
from dataclasses import dataclass
import hashlib
import jwt
from datetime import datetime, timedelta

class SecurityLayer(Enum):
    """å®‰å…¨é˜²ç¦¦å±¤ç´š"""
    PERIMETER = "perimeter"          # å‘¨é‚Šå®‰å…¨ (é˜²ç«ç‰†ã€WAF)
    IDENTITY = "identity"            # èº«ä»½èªè­‰ (MFAã€SSO)
    ACCESS = "access"                # è¨ªå•æ§åˆ¶ (RBACã€ABAC)
    APPLICATION = "application"      # æ‡‰ç”¨å®‰å…¨ (è¼¸å…¥é©—è­‰ã€è¼¸å‡ºéæ¿¾)
    DATA = "data"                    # æ•¸æ“šå®‰å…¨ (åŠ å¯†ã€DLP)
    MONITORING = "monitoring"        # å®‰å…¨ç›£æ§ (SIEMã€å¯©è¨ˆ)

@dataclass
class SecurityPolicy:
    """å®‰å…¨æ”¿ç­–æ•¸æ“šçµæ§‹"""
    policy_id: str
    name: str
    description: str
    layer: SecurityLayer
    rules: List[Dict]
    enforcement_level: str  # advisory, warning, blocking
    applicable_resources: List[str]
    exceptions: List[Dict]

class ZeroTrustSecurityFramework:
    """é›¶ä¿¡ä»»å®‰å…¨æ¡†æ¶"""

    def __init__(self):
        self.security_layers = {layer: [] for layer in SecurityLayer}
        self.policy_engine = PolicyEngine()
        self.context_analyzer = ContextAnalyzer()
        self.risk_calculator = RiskCalculator()

    async def evaluate_access_request(self, request: Dict) -> Dict:
        """è©•ä¼°è¨ªå•è«‹æ±‚"""

        # 1. èº«ä»½é©—è­‰
        identity_verification = await self._verify_identity(request["subject"])

        if not identity_verification["verified"]:
            return {
                "access_granted": False,
                "reason": "Identity verification failed",
                "verification_details": identity_verification
            }

        # 2. ä¸Šä¸‹æ–‡åˆ†æ
        context_analysis = await self.context_analyzer.analyze_request_context(request)

        # 3. é¢¨éšªè©•ä¼°
        risk_assessment = await self.risk_calculator.calculate_access_risk(
            request, identity_verification, context_analysis
        )

        # 4. æ”¿ç­–è©•ä¼°
        policy_evaluation = await self._evaluate_all_policies(
            request, context_analysis, risk_assessment
        )

        # 5. æœ€çµ‚æ±ºç­–
        access_decision = await self._make_access_decision(
            identity_verification, risk_assessment, policy_evaluation
        )

        return {
            "access_granted": access_decision["granted"],
            "reason": access_decision["reason"],
            "identity_verification": identity_verification,
            "context_analysis": context_analysis,
            "risk_assessment": risk_assessment,
            "policy_evaluation": policy_evaluation,
            "session_token": access_decision.get("session_token"),
            "access_duration": access_decision.get("access_duration")
        }

    async def _verify_identity(self, subject: Dict) -> Dict:
        """å¤šå› å­èº«ä»½é©—è­‰"""

        verification_factors = []

        # ç¬¬ä¸€å› å­: å¯†ç¢¼æˆ–è­‰æ›¸
        primary_auth = await self._verify_primary_credential(subject)
        verification_factors.append(("primary", primary_auth))

        # ç¬¬äºŒå› å­: MFA (å¦‚æœéœ€è¦)
        if self._requires_mfa(subject):
            mfa_result = await self._verify_mfa(subject)
            verification_factors.append(("mfa", mfa_result))

        # ç¬¬ä¸‰å› å­: è¨­å‚™ä¿¡ä»» (å¦‚æœé…ç½®)
        if self._requires_device_verification(subject):
            device_verification = await self._verify_device_trust(subject)
            verification_factors.append(("device", device_verification))

        # ç¶œåˆé©—è­‰çµæœ
        all_factors_passed = all(result["verified"] for _, result in verification_factors)

        verification_strength = sum(
            result["confidence"] for _, result in verification_factors
        ) / len(verification_factors)

        return {
            "verified": all_factors_passed,
            "verification_factors": dict(verification_factors),
            "verification_strength": verification_strength,
            "multi_factor_used": len(verification_factors) > 1
        }

    async def _evaluate_all_policies(self, request: Dict,
                                   context: Dict,
                                   risk: Dict) -> Dict:
        """è©•ä¼°æ‰€æœ‰é©ç”¨çš„å®‰å…¨æ”¿ç­–"""

        applicable_policies = await self._find_applicable_policies(request)

        policy_results = {}
        overall_compliance = True

        for policy in applicable_policies:
            policy_result = await self.policy_engine.evaluate_policy(
                policy, request, context, risk
            )

            policy_results[policy.policy_id] = policy_result

            if policy_result["enforcement_level"] == "blocking" and not policy_result["compliant"]:
                overall_compliance = False

        return {
            "overall_compliance": overall_compliance,
            "policy_results": policy_results,
            "total_policies_evaluated": len(applicable_policies),
            "blocking_violations": [
                policy_id for policy_id, result in policy_results.items()
                if result["enforcement_level"] == "blocking" and not result["compliant"]
            ]
        }

    async def _make_access_decision(self, identity: Dict, risk: Dict, policies: Dict) -> Dict:
        """åšå‡ºæœ€çµ‚è¨ªå•æ±ºç­–"""

        # æ±ºç­–é‚è¼¯
        if not identity["verified"]:
            return {"granted": False, "reason": "Identity verification failed"}

        if not policies["overall_compliance"]:
            return {
                "granted": False,
                "reason": "Policy violations detected",
                "violations": policies["blocking_violations"]
            }

        if risk["risk_level"] == "critical":
            return {"granted": False, "reason": "Risk level too high"}

        # è¨ˆç®—è¨ªå•æ¬Šé™ç´šåˆ¥
        access_level = self._calculate_access_level(identity, risk, policies)

        # ç”Ÿæˆæœƒè©±ä»¤ç‰Œ
        session_token = await self._generate_session_token(identity, access_level)

        # ç¢ºå®šè¨ªå•æœŸé™
        access_duration = self._calculate_access_duration(risk["risk_level"], access_level)

        return {
            "granted": True,
            "reason": "All security checks passed",
            "access_level": access_level,
            "session_token": session_token,
            "access_duration": access_duration
        }
```

---

## 2. å€‹äººè³‡æ–™ä¿è­·èˆ‡éš±ç§å·¥ç¨‹

### 2.1 PII æª¢æ¸¬çš„ç†è«–åŸºç¤

#### **éš±ç§æ•æ„Ÿåº¦çš„æ•¸å­¸æ¨¡å‹**

**å®šç¾© 2.1** (éš±ç§æ•æ„Ÿåº¦): å°æ–¼è³‡æ–™å…ƒç´  $d$ï¼Œå…¶éš±ç§æ•æ„Ÿåº¦å®šç¾©ç‚ºï¼š

$$\text{Sensitivity}(d) = \alpha \cdot \text{Identifiability}(d) + \beta \cdot \text{Linkability}(d) + \gamma \cdot \text{Inference}(d)$$

å…¶ä¸­ï¼š
- $\text{Identifiability}(d)$: ç›´æ¥è­˜åˆ¥å€‹äººçš„èƒ½åŠ›
- $\text{Linkability}(d)$: èˆ‡å…¶ä»–æ•¸æ“šé—œè¯çš„èƒ½åŠ›
- $\text{Inference}(d)$: æ¨æ–·é¡å¤–è³‡è¨Šçš„èƒ½åŠ›

**å®šç† 2.1** (k-åŒ¿åæ€§): è³‡æ–™é›† $D$ æ»¿è¶³ k-åŒ¿åæ€§ç•¶ä¸”åƒ…ç•¶ï¼š

$$\forall d \in D: |\{d' \in D : \text{QI}(d) = \text{QI}(d')\}| \geq k$$

å…¶ä¸­ $\text{QI}(d)$ ç‚ºæº–è­˜åˆ¥ç¬¦é›†åˆã€‚

#### **ä¼æ¥­ç´š PII æª¢æ¸¬ç³»çµ±**

```python
from presidio_analyzer import AnalyzerEngine, PatternRecognizer, EntityRecognizer
from presidio_anonymizer import AnonymizerEngine, OperatorConfig
import spacy
from typing import Dict, List, Any, Optional
import re

class EnterprisePIIDetector:
    """ä¼æ¥­ç´š PII æª¢æ¸¬ç³»çµ±"""

    def __init__(self):
        # åˆå§‹åŒ– Presidio åˆ†æå™¨
        self.analyzer = AnalyzerEngine()
        self.anonymizer = AnonymizerEngine()

        # æ·»åŠ ä¼æ¥­ç‰¹å®šå¯¦é«”è­˜åˆ¥å™¨
        self._add_enterprise_recognizers()

        # é¢¨éšªåˆ†ç´šé…ç½®
        self.risk_levels = {
            "CRITICAL": ["SSN", "CREDIT_CARD", "BANK_ACCOUNT", "PASSPORT"],
            "HIGH": ["PHONE_NUMBER", "EMAIL_ADDRESS", "EMPLOYEE_ID", "MEDICAL_RECORD"],
            "MEDIUM": ["PERSON", "IP_ADDRESS", "LOCATION"],
            "LOW": ["ORGANIZATION", "DATE_TIME"]
        }

    def _add_enterprise_recognizers(self):
        """æ·»åŠ ä¼æ¥­ç‰¹å®šçš„ PII è­˜åˆ¥å™¨"""

        # å“¡å·¥ ID è­˜åˆ¥å™¨
        employee_id_recognizer = PatternRecognizer(
            supported_entity="EMPLOYEE_ID",
            patterns=[{
                "name": "employee_id_pattern",
                "regex": r"\b(?:EMP|EMPL|E)-?\d{6,8}\b",
                "score": 0.85
            }]
        )

        # å®¢æˆ¶ ID è­˜åˆ¥å™¨
        customer_id_recognizer = PatternRecognizer(
            supported_entity="CUSTOMER_ID",
            patterns=[{
                "name": "customer_id_pattern",
                "regex": r"\b(?:CUST|CST|C)-?\d{8,12}\b",
                "score": 0.85
            }]
        )

        # é …ç›®ä»£ç¢¼è­˜åˆ¥å™¨
        project_code_recognizer = PatternRecognizer(
            supported_entity="PROJECT_CODE",
            patterns=[{
                "name": "project_code_pattern",
                "regex": r"\b(?:PROJ|PRJ)-[A-Z]{2,4}-\d{4}\b",
                "score": 0.90
            }]
        )

        # å…§éƒ¨ URL è­˜åˆ¥å™¨
        internal_url_recognizer = PatternRecognizer(
            supported_entity="INTERNAL_URL",
            patterns=[{
                "name": "internal_url_pattern",
                "regex": r"https?://[\w\-\.]+\.(?:company\.com|internal\.net)[/\w\-\.]*",
                "score": 0.95
            }]
        )

        # è¨»å†Šè­˜åˆ¥å™¨
        recognizers = [
            employee_id_recognizer,
            customer_id_recognizer,
            project_code_recognizer,
            internal_url_recognizer
        ]

        for recognizer in recognizers:
            self.analyzer.registry.add_recognizer(recognizer)

    async def comprehensive_pii_analysis(self, text: str,
                                       context: Dict = None) -> Dict:
        """å…¨é¢ PII åˆ†æ"""

        # 1. åŸºç¤ PII æª¢æ¸¬
        analyzer_results = self.analyzer.analyze(
            text=text,
            language="en",
            entities=self._get_detection_entities(context),
            return_decision_process=True
        )

        # 2. é¢¨éšªç­‰ç´šè©•ä¼°
        risk_assessment = await self._assess_pii_risk(analyzer_results, context)

        # 3. åˆè¦è¦æ±‚åˆ†æ
        compliance_requirements = await self._analyze_compliance_requirements(
            analyzer_results, context
        )

        # 4. åŒ¿ååŒ–å»ºè­°
        anonymization_plan = await self._create_anonymization_plan(
            analyzer_results, risk_assessment, compliance_requirements
        )

        return {
            "detected_entities": self._format_detection_results(analyzer_results),
            "risk_assessment": risk_assessment,
            "compliance_requirements": compliance_requirements,
            "anonymization_plan": anonymization_plan,
            "privacy_score": self._calculate_privacy_score(risk_assessment)
        }

    async def _assess_pii_risk(self, analyzer_results: List,
                             context: Dict = None) -> Dict:
        """è©•ä¼° PII é¢¨éšªç­‰ç´š"""

        risk_factors = {
            "entity_types": [],
            "entity_count": len(analyzer_results),
            "high_risk_count": 0,
            "cross_reference_potential": 0.0
        }

        # çµ±è¨ˆä¸åŒé¡å‹çš„å¯¦é«”
        entity_type_counts = {}
        for result in analyzer_results:
            entity_type = result.entity_type
            entity_type_counts[entity_type] = entity_type_counts.get(entity_type, 0) + 1

            # è¨ˆç®—é¢¨éšªç­‰ç´š
            for risk_level, entity_types in self.risk_levels.items():
                if entity_type in entity_types:
                    risk_factors["entity_types"].append((entity_type, risk_level))
                    if risk_level in ["CRITICAL", "HIGH"]:
                        risk_factors["high_risk_count"] += 1

        # è©•ä¼°äº¤å‰å¼•ç”¨é¢¨éšª
        if len(entity_type_counts) > 1:
            # å¤šç¨®é¡å‹çš„ PII å­˜åœ¨äº¤å‰å¼•ç”¨é¢¨éšª
            risk_factors["cross_reference_potential"] = min(1.0, len(entity_type_counts) / 5.0)

        # è¨ˆç®—ç¸½é«”é¢¨éšªç­‰ç´š
        if risk_factors["high_risk_count"] > 0:
            overall_risk = "HIGH"
        elif risk_factors["entity_count"] >= 5:
            overall_risk = "MEDIUM"
        elif risk_factors["entity_count"] >= 1:
            overall_risk = "LOW"
        else:
            overall_risk = "NONE"

        return {
            "overall_risk_level": overall_risk,
            "risk_factors": risk_factors,
            "entity_distribution": entity_type_counts,
            "requires_anonymization": overall_risk in ["HIGH", "MEDIUM"],
            "requires_approval": overall_risk == "HIGH"
        }

    async def _analyze_compliance_requirements(self, analyzer_results: List,
                                             context: Dict = None) -> Dict:
        """åˆ†æåˆè¦è¦æ±‚"""

        compliance_frameworks = {}

        detected_entity_types = set(result.entity_type for result in analyzer_results)

        # GDPR åˆ†æ
        gdpr_entities = {"PERSON", "EMAIL_ADDRESS", "PHONE_NUMBER", "IP_ADDRESS"}
        if detected_entity_types & gdpr_entities:
            compliance_frameworks["GDPR"] = {
                "applicable": True,
                "triggered_by": list(detected_entity_types & gdpr_entities),
                "requirements": [
                    "æ•¸æ“šè™•ç†æ³•å¾‹åŸºç¤",
                    "æ•¸æ“šä¸»é«”æ¬Šåˆ©å¯¦æ–½",
                    "æ•¸æ“šä¿è­·å½±éŸ¿è©•ä¼°",
                    "åŒæ„ç®¡ç†æ©Ÿåˆ¶"
                ]
            }

        # HIPAA åˆ†æ
        hipaa_entities = {"MEDICAL_RECORD", "PATIENT_ID", "HEALTH_INFO"}
        if detected_entity_types & hipaa_entities or context.get("domain") == "healthcare":
            compliance_frameworks["HIPAA"] = {
                "applicable": True,
                "triggered_by": list(detected_entity_types & hipaa_entities),
                "requirements": [
                    "æ¥­å‹™å¤¥ä¼´å”è­° (BAA)",
                    "æœ€å°å¿…è¦åŸå‰‡",
                    "åŠ å¯†è¦æ±‚",
                    "å¯©è¨ˆè¿½è¹¤"
                ]
            }

        # PCI DSS åˆ†æ
        pci_entities = {"CREDIT_CARD", "BANK_ACCOUNT"}
        if detected_entity_types & pci_entities:
            compliance_frameworks["PCI_DSS"] = {
                "applicable": True,
                "triggered_by": list(detected_entity_types & pci_entities),
                "requirements": [
                    "æ•¸æ“šåŠ å¯†",
                    "ç¶²çµ¡åˆ†å‰²",
                    "è¨ªå•æ§åˆ¶",
                    "å®šæœŸå®‰å…¨æ¸¬è©¦"
                ]
            }

        return compliance_frameworks

    async def intelligent_anonymization(self, text: str,
                                      pii_analysis: Dict,
                                      anonymization_strategy: str = "adaptive") -> Dict:
        """æ™ºèƒ½åŒ¿ååŒ–è™•ç†"""

        detected_entities = pii_analysis["detected_entities"]
        risk_level = pii_analysis["risk_assessment"]["overall_risk_level"]

        # æ ¹æ“šé¢¨éšªç­‰ç´šé¸æ“‡åŒ¿ååŒ–ç­–ç•¥
        if anonymization_strategy == "adaptive":
            if risk_level == "HIGH":
                strategy = "redaction"     # å®Œå…¨é®è”½
            elif risk_level == "MEDIUM":
                strategy = "replacement"   # æ›¿æ›ç‚ºé¡å‹æ¨™ç±¤
            else:
                strategy = "masking"       # éƒ¨åˆ†é®è”½
        else:
            strategy = anonymization_strategy

        # é…ç½®åŒ¿ååŒ–æ“ä½œ
        anonymization_operators = self._configure_anonymization_operators(
            detected_entities, strategy
        )

        # åŸ·è¡ŒåŒ¿ååŒ–
        anonymization_result = self.anonymizer.anonymize(
            text=text,
            analyzer_results=detected_entities,
            operators=anonymization_operators
        )

        # é©—è­‰åŒ¿ååŒ–æ•ˆæœ
        post_anonymization_check = await self._verify_anonymization_completeness(
            anonymization_result.text, detected_entities
        )

        return {
            "anonymized_text": anonymization_result.text,
            "strategy_used": strategy,
            "entities_processed": len(detected_entities),
            "anonymization_items": [
                {
                    "entity_type": item.entity_type,
                    "original_text": item.text,
                    "anonymized_text": item.anonymized_text,
                    "operator": item.operator
                }
                for item in anonymization_result.items
            ],
            "completeness_verification": post_anonymization_check
        }

    def _configure_anonymization_operators(self, entities: List,
                                         strategy: str) -> Dict[str, OperatorConfig]:
        """é…ç½®åŒ¿ååŒ–æ“ä½œå™¨"""

        operators = {}

        for entity in entities:
            entity_type = entity.entity_type

            if strategy == "redaction":
                operators[entity_type] = OperatorConfig("redact", {"new_value": "[REDACTED]"})

            elif strategy == "replacement":
                replacement_values = {
                    "PERSON": "[PERSON]",
                    "EMAIL_ADDRESS": "[EMAIL]",
                    "PHONE_NUMBER": "[PHONE]",
                    "EMPLOYEE_ID": "[EMP_ID]",
                    "CUSTOMER_ID": "[CUSTOMER_ID]",
                    "CREDIT_CARD": "[CREDIT_CARD]",
                    "SSN": "[SSN]",
                    "IP_ADDRESS": "[IP_ADDRESS]"
                }

                replacement_value = replacement_values.get(entity_type, f"[{entity_type}]")
                operators[entity_type] = OperatorConfig("replace", {"new_value": replacement_value})

            elif strategy == "masking":
                if entity_type in ["EMAIL_ADDRESS", "PHONE_NUMBER"]:
                    operators[entity_type] = OperatorConfig("mask", {
                        "masking_char": "*",
                        "chars_to_mask": 4,
                        "from_end": False
                    })
                elif entity_type == "CREDIT_CARD":
                    operators[entity_type] = OperatorConfig("mask", {
                        "masking_char": "*",
                        "chars_to_mask": 12,
                        "from_end": False
                    })
                else:
                    operators[entity_type] = OperatorConfig("replace", {"new_value": f"[{entity_type}]"})

        return operators
```

---

## 3. ä¼æ¥­åˆè¦è‡ªå‹•åŒ–

### 3.1 GDPR åˆè¦çš„æŠ€è¡“å¯¦ç¾

#### **æ•¸æ“šä¸»é«”æ¬Šåˆ©çš„ç³»çµ±åŒ–å¯¦ç¾**

**æ¬Šåˆ© 3.1** (GDPR æ•¸æ“šä¸»é«”æ¬Šåˆ©çš„æŠ€è¡“æ˜ å°„):

| GDPR æ¬Šåˆ© | æŠ€è¡“å¯¦ç¾ | ç³»çµ±çµ„ä»¶ |
|-----------|---------|---------|
| **è¨ªå•æ¬Š** (Art. 15) | æ•¸æ“šå°å‡º API | ç”¨æˆ¶æ•¸æ“šæŸ¥è©¢ç³»çµ± |
| **æ›´æ­£æ¬Š** (Art. 16) | æ•¸æ“šä¿®æ”¹ API | å‘é‡ç´¢å¼•æ›´æ–°æ©Ÿåˆ¶ |
| **åˆªé™¤æ¬Š** (Art. 17) | æ•¸æ“šåˆªé™¤ API | åˆ†æ•£å¼æ•¸æ“šæ¸…ç† |
| **å¯æ”œæ€§æ¬Š** (Art. 20) | æ¨™æº–æ ¼å¼å°å‡º | æ•¸æ“šåºåˆ—åŒ–ç³»çµ± |

```python
from typing import Dict, List, Optional, Any
from dataclasses import dataclass
from datetime import datetime, timedelta
import asyncio
import json

@dataclass
class DataSubjectRequest:
    """æ•¸æ“šä¸»é«”è«‹æ±‚"""
    request_id: str
    request_type: str  # access, rectification, erasure, portability
    data_subject_id: str
    request_details: Dict
    submitted_at: datetime
    status: str
    processed_by: Optional[str]

class GDPRComplianceManager:
    """GDPR åˆè¦ç®¡ç†å™¨"""

    def __init__(self):
        self.data_inventory = DataInventoryManager()
        self.consent_manager = ConsentManager()
        self.audit_logger = AuditLogger()
        self.notification_system = NotificationSystem()

    async def handle_data_subject_request(self, request: DataSubjectRequest) -> Dict:
        """è™•ç†æ•¸æ“šä¸»é«”è«‹æ±‚"""

        # 1. èº«ä»½é©—è­‰
        identity_verification = await self._verify_data_subject_identity(
            request.data_subject_id, request.request_details
        )

        if not identity_verification["verified"]:
            return {
                "status": "rejected",
                "reason": "èº«ä»½é©—è­‰å¤±æ•—",
                "verification_details": identity_verification
            }

        # 2. è«‹æ±‚æœ‰æ•ˆæ€§æª¢æŸ¥
        validity_check = await self._validate_request(request)

        if not validity_check["valid"]:
            return {
                "status": "rejected",
                "reason": "è«‹æ±‚ç„¡æ•ˆ",
                "validation_details": validity_check
            }

        # 3. æ•¸æ“šç¯„åœç¢ºå®š
        data_scope = await self._determine_data_scope(request)

        # 4. åŸ·è¡Œæ•¸æ“šä¸»é«”æ¬Šåˆ©
        execution_result = await self._execute_data_subject_right(request, data_scope)

        # 5. å¯©è¨ˆè¨˜éŒ„
        await self.audit_logger.log_data_subject_request(
            request, execution_result, identity_verification
        )

        # 6. é€šçŸ¥ç›¸é—œæ–¹
        await self._notify_stakeholders(request, execution_result)

        return {
            "status": "completed",
            "request_id": request.request_id,
            "execution_result": execution_result,
            "completion_time": datetime.now(),
            "audit_trail_id": execution_result.get("audit_trail_id")
        }

    async def _execute_data_subject_right(self, request: DataSubjectRequest,
                                        data_scope: Dict) -> Dict:
        """åŸ·è¡Œæ•¸æ“šä¸»é«”æ¬Šåˆ©"""

        execution_results = {}

        if request.request_type == "access":
            # æ•¸æ“šè¨ªå•æ¬Šå¯¦ç¾
            access_result = await self._execute_access_right(request, data_scope)
            execution_results["access_result"] = access_result

        elif request.request_type == "rectification":
            # æ•¸æ“šæ›´æ­£æ¬Šå¯¦ç¾
            rectification_result = await self._execute_rectification_right(request, data_scope)
            execution_results["rectification_result"] = rectification_result

        elif request.request_type == "erasure":
            # æ•¸æ“šåˆªé™¤æ¬Šå¯¦ç¾ (è¢«éºå¿˜æ¬Š)
            erasure_result = await self._execute_erasure_right(request, data_scope)
            execution_results["erasure_result"] = erasure_result

        elif request.request_type == "portability":
            # æ•¸æ“šå¯æ”œæ€§æ¬Šå¯¦ç¾
            portability_result = await self._execute_portability_right(request, data_scope)
            execution_results["portability_result"] = portability_result

        return execution_results

    async def _execute_erasure_right(self, request: DataSubjectRequest,
                                   data_scope: Dict) -> Dict:
        """åŸ·è¡Œæ•¸æ“šåˆªé™¤æ¬Š (æŠ€è¡“å¯¦ç¾)"""

        data_subject_id = request.data_subject_id
        erasure_results = {}

        # 1. æ–‡æª”å…§å®¹ä¸­çš„å€‹äººæ•¸æ“šåˆªé™¤
        document_erasure = await self._erase_from_documents(
            data_subject_id, data_scope["documents"]
        )
        erasure_results["documents"] = document_erasure

        # 2. å‘é‡ç´¢å¼•ä¸­çš„æ•¸æ“šåˆªé™¤
        vector_erasure = await self._erase_from_vector_index(
            data_subject_id, data_scope["vector_data"]
        )
        erasure_results["vector_index"] = vector_erasure

        # 3. å…ƒæ•¸æ“šå’Œæ—¥èªŒä¸­çš„æ•¸æ“šåˆªé™¤
        metadata_erasure = await self._erase_from_metadata(
            data_subject_id, data_scope["metadata"]
        )
        erasure_results["metadata"] = metadata_erasure

        # 4. å¯©è¨ˆæ—¥èªŒçš„ç‰¹æ®Šè™•ç† (æ³•å¾‹è¦æ±‚ä¿ç•™)
        audit_processing = await self._process_audit_logs_for_erasure(
            data_subject_id, data_scope["audit_logs"]
        )
        erasure_results["audit_logs"] = audit_processing

        # 5. ç¬¬ä¸‰æ–¹ç³»çµ±é€šçŸ¥
        third_party_notifications = await self._notify_third_party_processors(
            data_subject_id, request
        )
        erasure_results["third_party_notifications"] = third_party_notifications

        # 6. é©—è­‰åˆªé™¤å®Œæ•´æ€§
        verification_result = await self._verify_erasure_completeness(
            data_subject_id, erasure_results
        )

        return {
            "erasure_results": erasure_results,
            "verification": verification_result,
            "completeness_score": verification_result["completeness_percentage"],
            "estimated_impact": self._estimate_erasure_impact(erasure_results)
        }

    async def _erase_from_vector_index(self, data_subject_id: str,
                                     vector_data_scope: Dict) -> Dict:
        """å¾å‘é‡ç´¢å¼•ä¸­åˆªé™¤æ•¸æ“š"""

        erasure_stats = {
            "vectors_examined": 0,
            "vectors_deleted": 0,
            "collections_affected": [],
            "indexes_rebuilt": []
        }

        for collection_name, vector_ids in vector_data_scope.items():
            try:
                # æŸ¥è©¢åŒ…å«å€‹äººæ•¸æ“šçš„å‘é‡
                affected_vectors = await self._identify_personal_vectors(
                    collection_name, data_subject_id
                )

                erasure_stats["vectors_examined"] += len(affected_vectors)

                # åˆªé™¤å‘é‡
                if affected_vectors:
                    deletion_result = await self._delete_vectors_from_collection(
                        collection_name, affected_vectors
                    )

                    erasure_stats["vectors_deleted"] += deletion_result["deleted_count"]
                    erasure_stats["collections_affected"].append(collection_name)

                    # å¦‚æœåˆªé™¤é‡å¤§ï¼Œé‡å»ºç´¢å¼•ä»¥å„ªåŒ–æ€§èƒ½
                    if deletion_result["deleted_count"] > 1000:
                        rebuild_result = await self._rebuild_vector_index(collection_name)
                        if rebuild_result["success"]:
                            erasure_stats["indexes_rebuilt"].append(collection_name)

            except Exception as e:
                erasure_stats[f"error_{collection_name}"] = str(e)

        return erasure_stats

    async def _verify_erasure_completeness(self, data_subject_id: str,
                                         erasure_results: Dict) -> Dict:
        """é©—è­‰åˆªé™¤å®Œæ•´æ€§"""

        verification_checks = {}

        # 1. æ–‡æª”æœç´¢é©—è­‰
        doc_search_result = await self._search_for_personal_data_in_documents(data_subject_id)
        verification_checks["document_search"] = {
            "data_found": len(doc_search_result) > 0,
            "found_locations": doc_search_result
        }

        # 2. å‘é‡ç´¢å¼•æœç´¢é©—è­‰
        vector_search_result = await self._search_for_personal_data_in_vectors(data_subject_id)
        verification_checks["vector_search"] = {
            "data_found": len(vector_search_result) > 0,
            "found_vectors": vector_search_result
        }

        # 3. å…ƒæ•¸æ“šæª¢æŸ¥
        metadata_check = await self._check_metadata_for_personal_data(data_subject_id)
        verification_checks["metadata_check"] = metadata_check

        # è¨ˆç®—å®Œæ•´æ€§ç™¾åˆ†æ¯”
        total_checks = len(verification_checks)
        passed_checks = sum(1 for check in verification_checks.values()
                          if not check.get("data_found", True))

        completeness_percentage = (passed_checks / total_checks) * 100

        return {
            "verification_checks": verification_checks,
            "completeness_percentage": completeness_percentage,
            "fully_compliant": completeness_percentage == 100,
            "remaining_data_locations": self._identify_remaining_data(verification_checks)
        }

class SOC2ComplianceFramework:
    """SOC2 åˆè¦æ¡†æ¶"""

    def __init__(self):
        self.trust_service_criteria = {
            "security": SecurityControlFramework(),
            "availability": AvailabilityControlFramework(),
            "processing_integrity": ProcessingIntegrityFramework(),
            "confidentiality": ConfidentialityFramework(),
            "privacy": PrivacyFramework()
        }

    async def assess_soc2_compliance(self, system_config: Dict) -> Dict:
        """è©•ä¼° SOC2 åˆè¦ç‹€æ³"""

        compliance_assessment = {}

        for criterion, framework in self.trust_service_criteria.items():
            criterion_assessment = await framework.assess_compliance(system_config)
            compliance_assessment[criterion] = criterion_assessment

        # è¨ˆç®—ç¸½é«”åˆè¦åˆ†æ•¸
        overall_score = sum(
            assessment["compliance_score"]
            for assessment in compliance_assessment.values()
        ) / len(compliance_assessment)

        # è­˜åˆ¥åˆè¦å·®è·
        compliance_gaps = []
        for criterion, assessment in compliance_assessment.items():
            for control in assessment["control_assessments"]:
                if not control["implemented"]:
                    compliance_gaps.append({
                        "criterion": criterion,
                        "control": control["control_id"],
                        "description": control["description"],
                        "priority": control["priority"],
                        "implementation_effort": control["estimated_effort"]
                    })

        return {
            "overall_compliance_score": overall_score,
            "criterion_assessments": compliance_assessment,
            "compliance_gaps": compliance_gaps,
            "readiness_level": self._classify_soc2_readiness(overall_score),
            "remediation_plan": self._create_soc2_remediation_plan(compliance_gaps)
        }
```

---

## 4. å®‰å…¨ç›£æ§èˆ‡äº‹ä»¶å›æ‡‰

### 4.1 å®‰å…¨äº‹ä»¶æª¢æ¸¬ç†è«–

#### **ç•°å¸¸æª¢æ¸¬çš„çµ±è¨ˆæ¨¡å‹**

**å®šç¾© 4.1** (å®‰å…¨ç•°å¸¸): çµ¦å®šæ­£å¸¸è¡Œç‚ºæ¨¡å¼çš„æ¦‚ç‡åˆ†ä½ˆ $P(\text{Normal})$ï¼Œå®‰å…¨ç•°å¸¸å®šç¾©ç‚ºï¼š

$$\text{Anomaly} = \{x : P(x | \text{Normal}) < \tau\}$$

å…¶ä¸­ $\tau$ ç‚ºç•°å¸¸æª¢æ¸¬é–¾å€¼ã€‚

**ç®—æ³• 4.1** (åŸºæ–¼æ©Ÿå™¨å­¸ç¿’çš„ç•°å¸¸æª¢æ¸¬):

```python
from sklearn.ensemble import IsolationForest
from sklearn.preprocessing import StandardScaler
import numpy as np
from typing import Dict, List, Any
from datetime import datetime

class SecurityAnomalyDetector:
    """å®‰å…¨ç•°å¸¸æª¢æ¸¬å™¨"""

    def __init__(self):
        # ç•°å¸¸æª¢æ¸¬æ¨¡å‹
        self.isolation_forest = IsolationForest(
            contamination=0.1,  # é æœŸç•°å¸¸æ¯”ä¾‹
            random_state=42,
            n_estimators=100
        )

        # ç‰¹å¾µæ¨™æº–åŒ–å™¨
        self.scaler = StandardScaler()

        # è¡Œç‚ºåŸºç·š
        self.behavior_baselines = {}

        # ç•°å¸¸é¡å‹åˆ†é¡å™¨
        self.anomaly_classifier = AnomalyTypeClassifier()

    async def train_anomaly_detector(self, training_data: List[Dict]) -> Dict:
        """è¨“ç·´ç•°å¸¸æª¢æ¸¬æ¨¡å‹"""

        # 1. ç‰¹å¾µå·¥ç¨‹
        feature_matrix = await self._extract_security_features(training_data)

        # 2. æ•¸æ“šé è™•ç†
        scaled_features = self.scaler.fit_transform(feature_matrix)

        # 3. æ¨¡å‹è¨“ç·´
        self.isolation_forest.fit(scaled_features)

        # 4. å»ºç«‹è¡Œç‚ºåŸºç·š
        self.behavior_baselines = await self._establish_behavior_baselines(training_data)

        # 5. æ¨¡å‹é©—è­‰
        validation_result = await self._validate_anomaly_model(training_data)

        return {
            "training_samples": len(training_data),
            "feature_dimensions": feature_matrix.shape[1],
            "model_performance": validation_result,
            "baseline_establishment": "completed"
        }

    async def detect_security_anomalies(self, current_activity: List[Dict]) -> Dict:
        """æª¢æ¸¬å®‰å…¨ç•°å¸¸"""

        if not current_activity:
            return {"anomalies": [], "normal_activities": 0}

        # 1. ç‰¹å¾µæå–
        activity_features = await self._extract_security_features(current_activity)

        # 2. ç‰¹å¾µæ¨™æº–åŒ–
        scaled_features = self.scaler.transform(activity_features)

        # 3. ç•°å¸¸æª¢æ¸¬
        anomaly_scores = self.isolation_forest.decision_function(scaled_features)
        anomaly_predictions = self.isolation_forest.predict(scaled_features)

        # 4. çµæœåˆ†æ
        anomalies = []
        for i, (score, prediction) in enumerate(zip(anomaly_scores, anomaly_predictions)):
            if prediction == -1:  # ç•°å¸¸
                activity_data = current_activity[i]

                # åˆ†é¡ç•°å¸¸é¡å‹
                anomaly_type = await self.anomaly_classifier.classify_anomaly(
                    activity_data, score
                )

                anomaly_info = {
                    "activity_id": activity_data.get("id", f"activity_{i}"),
                    "anomaly_score": float(score),
                    "anomaly_type": anomaly_type,
                    "activity_data": activity_data,
                    "severity": self._calculate_anomaly_severity(score, anomaly_type),
                    "detected_at": datetime.now()
                }

                anomalies.append(anomaly_info)

        # 5. ç•°å¸¸èšåˆåˆ†æ
        anomaly_clusters = await self._cluster_related_anomalies(anomalies)

        return {
            "anomalies": anomalies,
            "anomaly_clusters": anomaly_clusters,
            "normal_activities": len(current_activity) - len(anomalies),
            "anomaly_rate": len(anomalies) / len(current_activity),
            "severity_distribution": self._analyze_severity_distribution(anomalies)
        }

    async def _extract_security_features(self, activities: List[Dict]) -> np.ndarray:
        """æå–å®‰å…¨ç›¸é—œç‰¹å¾µ"""

        features = []

        for activity in activities:
            activity_features = []

            # æ™‚é–“ç‰¹å¾µ
            timestamp = activity.get("timestamp", datetime.now())
            activity_features.extend([
                timestamp.hour,                    # å°æ™‚ (0-23)
                timestamp.weekday(),              # æ˜ŸæœŸ (0-6)
                (timestamp.hour >= 9 and timestamp.hour <= 17)  # å·¥ä½œæ™‚é–“ (boolean -> int)
            ])

            # ç”¨æˆ¶ç‰¹å¾µ
            user_info = activity.get("user", {})
            activity_features.extend([
                len(user_info.get("roles", [])),          # è§’è‰²æ•¸é‡
                len(user_info.get("departments", [])),    # éƒ¨é–€æ•¸é‡
                hash(user_info.get("location", "")) % 100 # ä½ç½®å“ˆå¸Œ
            ])

            # è¨ªå•ç‰¹å¾µ
            access_info = activity.get("access", {})
            activity_features.extend([
                len(access_info.get("resources", [])),    # è¨ªå•è³‡æºæ•¸é‡
                access_info.get("data_classification", 0), # æ•¸æ“šåˆ†é¡ç­‰ç´š
                access_info.get("session_duration", 0)   # æœƒè©±æŒçºŒæ™‚é–“
            ])

            # æŸ¥è©¢ç‰¹å¾µ
            query_info = activity.get("query", {})
            activity_features.extend([
                len(query_info.get("text", "")),         # æŸ¥è©¢é•·åº¦
                query_info.get("complexity_score", 0),   # æŸ¥è©¢è¤‡é›œåº¦
                len(query_info.get("results", []))       # çµæœæ•¸é‡
            ])

            features.append(activity_features)

        return np.array(features)

    def _calculate_anomaly_severity(self, score: float, anomaly_type: Dict) -> str:
        """è¨ˆç®—ç•°å¸¸åš´é‡ç¨‹åº¦"""

        base_severity = anomaly_type.get("base_severity", "medium")

        # æ ¹æ“šç•°å¸¸åˆ†æ•¸èª¿æ•´åš´é‡ç¨‹åº¦
        if score < -0.5:  # é«˜åº¦ç•°å¸¸
            if base_severity == "low":
                return "medium"
            elif base_severity == "medium":
                return "high"
            else:  # already high
                return "critical"
        elif score < -0.2:  # ä¸­åº¦ç•°å¸¸
            return base_severity
        else:  # è¼•åº¦ç•°å¸¸
            if base_severity == "high":
                return "medium"
            elif base_severity == "medium":
                return "low"
            else:
                return "low"

class SecurityEventResponseSystem:
    """å®‰å…¨äº‹ä»¶å›æ‡‰ç³»çµ±"""

    def __init__(self):
        self.incident_manager = IncidentManager()
        self.response_playbooks = ResponsePlaybookManager()
        self.communication_system = SecurityCommunicationSystem()

    async def handle_security_event(self, event: Dict) -> Dict:
        """è™•ç†å®‰å…¨äº‹ä»¶"""

        # 1. äº‹ä»¶åˆ†é¡å’Œå„ªå…ˆç´šåˆ†é…
        event_classification = await self._classify_security_event(event)

        # 2. é¸æ“‡éŸ¿æ‡‰åŠ‡æœ¬
        response_playbook = await self.response_playbooks.select_playbook(
            event_classification
        )

        # 3. è‡ªå‹•åŒ–éŸ¿æ‡‰
        automated_response = await self._execute_automated_response(
            event, response_playbook
        )

        # 4. äººå·¥ä»‹å…¥åˆ¤æ–·
        human_intervention = await self._assess_human_intervention_need(
            event, automated_response
        )

        # 5. é€šçŸ¥ç›¸é—œäººå“¡
        notification_result = await self.communication_system.notify_stakeholders(
            event, event_classification, human_intervention
        )

        return {
            "event_id": event.get("id", "unknown"),
            "classification": event_classification,
            "automated_response": automated_response,
            "human_intervention_required": human_intervention["required"],
            "notifications_sent": notification_result,
            "response_status": "handled"
        }
```

---

## 5. æœ¬ç« ç¸½çµ

### 5.1 å®‰å…¨åˆè¦è¦é»å›é¡§

1. **é›¶ä¿¡ä»»åŸå‰‡**: æ°¸ä¸ä¿¡ä»»ã€å§‹çµ‚é©—è­‰ã€æœ€å°æ¬Šé™çš„ç³»çµ±åŒ–å¯¦ç¾
2. **éš±ç§ä¿è­·**: åŸºæ–¼æ•¸å­¸æ¨¡å‹çš„ PII æª¢æ¸¬å’Œæ™ºèƒ½åŒ¿ååŒ–
3. **åˆè¦è‡ªå‹•åŒ–**: GDPRã€SOC2ã€HIPAA çš„æŠ€è¡“å¯¦ç¾æ¡†æ¶
4. **å®‰å…¨ç›£æ§**: åŸºæ–¼æ©Ÿå™¨å­¸ç¿’çš„ç•°å¸¸æª¢æ¸¬å’Œè‡ªå‹•åŒ–å›æ‡‰

### 5.2 å¯¦æ–½æœ€ä½³å¯¦è¸

1. **å®‰å…¨å„ªå…ˆè¨­è¨ˆ**: å¾ç³»çµ±è¨­è¨ˆåˆæœŸå°±å…§å»ºå®‰å…¨æ©Ÿåˆ¶
2. **åˆè¦å³ä»£ç¢¼**: å°‡åˆè¦è¦æ±‚è½‰åŒ–ç‚ºå¯è‡ªå‹•åŸ·è¡Œçš„ä»£ç¢¼
3. **æŒçºŒç›£æ§**: å»ºç«‹å…¨æ–¹ä½çš„å®‰å…¨ç›£æ§å’Œå‘Šè­¦é«”ç³»
4. **äº‹ä»¶æº–å‚™**: åˆ¶å®šå®Œæ•´çš„å®‰å…¨äº‹ä»¶å›æ‡‰é æ¡ˆ

### 5.3 ä¸‹ç« é å‘Š

ç¬¬7ç« å°‡æ¢è¨ GraphRAG å’Œå¤šæ™ºèƒ½é«”ç³»çµ±ï¼Œé€™äº›å…ˆé€²æŠ€è¡“ç‚º RAG ç³»çµ±å¸¶ä¾†äº†æ–°çš„å®‰å…¨æŒ‘æˆ°å’Œæ©Ÿé‡ï¼Œéœ€è¦åœ¨å®‰å…¨æ¡†æ¶ä¸­çµ¦äºˆç‰¹æ®Šè€ƒæ…®ã€‚

---

**èª²ç¨‹è©•ä¼°**: æœ¬ç« å…§å®¹åœ¨æœŸæœ«è€ƒè©¦ä¸­å 15%æ¬Šé‡ï¼Œé‡é»è€ƒæŸ¥å®‰å…¨è¨­è¨ˆæ€ç¶­å’Œåˆè¦å¯¦ç¾èƒ½åŠ›ã€‚

**å¯¦ä½œè¦æ±‚**: å­¸ç”Ÿéœ€è¨­è¨ˆä¸€å€‹ç¬¦åˆç‰¹å®šåˆè¦è¦æ±‚ (å¦‚ GDPR) çš„ RAG ç³»çµ±å®‰å…¨æ¶æ§‹ã€‚